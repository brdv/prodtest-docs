"use strict";(self.webpackChunkprodtest=self.webpackChunkprodtest||[]).push([[505],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},s=Object.keys(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=o.createContext({}),c=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},d=function(e){var t=c(e.components);return o.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),u=c(n),h=r,m=u["".concat(l,".").concat(h)]||u[h]||p[h]||s;return n?o.createElement(m,a(a({ref:t},d),{},{components:n})):o.createElement(m,a({ref:t},d))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=n.length,a=new Array(s);a[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,a[1]=i;for(var c=2;c<s;c++)a[c]=n[c];return o.createElement.apply(null,a)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},9046:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var o=n(7462),r=(n(7294),n(3905));const s={title:"Pipelines",sidebar_position:5},a=void 0,i={unversionedId:"demo/technical-detail/pipelines",id:"demo/technical-detail/pipelines",title:"Pipelines",description:"The prodtest-demo repository uses pipelines to do a few automatic checks on the codebase. This page describes what pipelines are used, why and how they are implemented.",source:"@site/docs/demo/technical-detail/pipelines.md",sourceDirName:"demo/technical-detail",slug:"/demo/technical-detail/pipelines",permalink:"/prodtest-docs/demo/technical-detail/pipelines",draft:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"Pipelines",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Data Separation",permalink:"/prodtest-docs/demo/technical-detail/data-separation"},next:{title:"Testing the project",permalink:"/prodtest-docs/demo/technical-detail/testing"}},l={},c=[{value:"Automated checks",id:"automated-checks",level:2},{value:"Workflows",id:"workflows",level:2},{value:"Solution level",id:"solution-level",level:3},{value:"Code conventions",id:"code-conventions",level:4},{value:"SonarScanner",id:"sonarscanner",level:4},{value:"Project level",id:"project-level",level:3}],d={toc:c};function p(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/brdv/prodtest-demo"},"prodtest-demo repository")," uses pipelines to do a few automatic checks on the codebase. This page describes what pipelines are used, why and how they are implemented."),(0,r.kt)("h2",{id:"automated-checks"},"Automated checks"),(0,r.kt)("p",null,"A pipeline is one or a set of processes that perform certain actions to your code base. Some examples are testing, building and deploying your code. The pipelines can be run automatically in many git providers. GitHub, the provider used for de demo project, has Actions (basically pipelines) to automate these checks. The main benefit of using these automated pipelines is that you can make sure code is not merged or deployed without passing all the specified checks."),(0,r.kt)("h2",{id:"workflows"},"Workflows"),(0,r.kt)("p",null,"In the demo project, there are a few checks implemented to assure code quality and functionality. These checks are implemented in so called workflow files. A distinction has been made between two types of workflows: one on the whole project/solution, and on per-service. The used workflows are as follows:"),(0,r.kt)("h3",{id:"solution-level"},"Solution level"),(0,r.kt)("p",null,"At solution level, two checks are conducted."),(0,r.kt)("h4",{id:"code-conventions"},"Code conventions"),(0,r.kt)("p",null,"First, the code is checked for code conventions. For this check ",(0,r.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-format"},"dotnet format")," is used. A rule set is defined in the ",(0,r.kt)("inlineCode",{parentName:"p"},".editorconfig")," file. This rule set is copied from the dotnet project. The implemented pipeline is as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},"lint-project:\n  name: Check Code Conventions\n  runs-on: ubuntu-latest\n  strategy:\n    matrix:\n      dotnet-version: ['6.x.x']\n  steps:\n    - uses: actions/checkout@v3\n    - name: Setup .NET Core SDK ${{ matrix.dotnet-version }}\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: ${{ matrix.dotnet-version }}\n    - name: Install dependencies\n      run: dotnet restore ./src\n    - name: Format\n      run: dotnet format --version && echo \"\\n\" && dotnet format style ./src --verbosity n --verify-no-changes --severity warn\n")),(0,r.kt)("p",null,"As you can see. It runs on ubuntu latest and runs the command ",(0,r.kt)("inlineCode",{parentName:"p"},'dotnet format --version && echo "\\n" && dotnet format style ./src --verbosity n --verify-no-changes --severity warn'),".\nIt asks for the version first, this is done for debugging purposes. The it formats the ",(0,r.kt)("inlineCode",{parentName:"p"},"./src")," folder to check for code style. The flags mean the following: ",(0,r.kt)("inlineCode",{parentName:"p"},"--verbosity n")," normal verbosity, has to be specified or no logs are shown; ",(0,r.kt)("inlineCode",{parentName:"p"},"--verify-no-changes"),", makes the pipeline fail if the code is formatted; --severity warn, formats everything that is specified as warning of up (error)."),(0,r.kt)("h4",{id:"sonarscanner"},"SonarScanner"),(0,r.kt)("p",null,"The second job in this workflow is running SonarScanner. SonarScanner is a SonarQube code scanner that checks multiple quality meassures. For example, it checks if there are any known bugs or code smells in the project. The sonarscanner job is implemented as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},'sonar:\n  name: Sonar\n  runs-on: ubuntu-latest\n  needs: lint-project\n  steps:\n    - name: Set up JDK 11\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.11\n    - uses: actions/checkout@v2\n      with:\n        fetch-depth: 0 # Shallow clones should be disabled for a better relevancy of analysis\n    - name: Cache SonarCloud packages\n      uses: actions/cache@v1\n      with:\n        path: ~\\sonar\\cache\n        key: ${{ runner.os }}-sonar\n        restore-keys: ${{ runner.os }}-sonar\n    - name: Install SonarCloud scanners\n      run: |\n        dotnet tool install --global dotnet-sonarscanner\n    - name: Build and analyze\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Needed to get PR information, if any\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n      run: |\n        dotnet-sonarscanner begin /k:"prodtest-demo" /o:"isbumpafstuderen" /d:sonar.login="${{ secrets.SONAR_TOKEN }}" /d:sonar.host.url="https://sonarcloud.io" /d:sonar.cs.opencover.reportsPaths=**/TestResults/**/coverage.opencover.xml\n        dotnet build ./src\n        dotnet test ./src --logger trx --collect:"XPlat Code Coverage" -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=opencover\n        dotnet-sonarscanner end /d:sonar.login="${{ secrets.SONAR_TOKEN }}"\n')),(0,r.kt)("p",null,"The final run command runs the scanner. It also adds code coverage on line 29 using coverlet. It pushes the results tot the prodtest-demo sonarcloud project."),(0,r.kt)("h3",{id:"project-level"},"Project level"),(0,r.kt)("p",null,"Each individual project has some checks that need to run per-project. This is to help identifying possible issues as quickly as possible. The jobs are: Mutation testing (with ",(0,r.kt)("a",{parentName:"p",href:"https://stryker-mutator.io"},"Stryker"),") and building. The workflow jobs are specified in the file 'service-check.yaml'. They can be used by other files, this looks as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},"name: OrderService\n\non:\n  pull_request:\n    branches:\n      - main\n      - 'sprint/**'\n\njobs:\n  run-checks:\n    uses: brdv/prodtest-demo/.github/workflows/service-check.yaml@sprint/4\n    with:\n      project_dir: 'src/Services/Order/Order.API'\n      test_project: 'src/Services/Order/Order.API.Tests/'\n")),(0,r.kt)("p",null,"On line 10, we use a yaml file in the repository itself. This way we can define the jobs once, and use them in multiple service-workflows."))}p.isMDXComponent=!0}}]);